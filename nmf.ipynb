{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_initialization(A,rank):\n",
    "    number_of_documents = A.shape[0]\n",
    "    number_of_terms = A.shape[1]\n",
    "    W = np.random.uniform(1,2,(number_of_documents,rank))\n",
    "    H = np.random.uniform(1,2,(rank,number_of_terms))\n",
    "    return W,H\n",
    "                          \n",
    "\n",
    "def nndsvd_initialization(A,rank):\n",
    "\n",
    "    u,s,v=np.linalg.svd(A,full_matrices=False)\n",
    "\n",
    "    v=v.T\n",
    "    w=np.zeros((A.shape[0],rank))\n",
    "    h=np.zeros((rank,A.shape[1]))\n",
    "\n",
    "    w[:,0]=np.sqrt(s[0])*np.abs(u[:,0])\n",
    "    h[0,:]=np.sqrt(s[0])*np.abs(v[:,0].T)\n",
    "\n",
    "    for i in range(1,rank):\n",
    "        \n",
    "        ui=u[:,i]\n",
    "        vi=v[:,i]\n",
    "        ui_pos=(ui>=0)*ui\n",
    "        ui_neg=(ui<0)*-ui\n",
    "        vi_pos=(vi>=0)*vi\n",
    "        vi_neg=(vi<0)*-vi\n",
    "        \n",
    "        ui_pos_norm=np.linalg.norm(ui_pos,2)\n",
    "        ui_neg_norm=np.linalg.norm(ui_neg,2)\n",
    "        vi_pos_norm=np.linalg.norm(vi_pos,2)\n",
    "        vi_neg_norm=np.linalg.norm(vi_neg,2)\n",
    "        \n",
    "        norm_pos=ui_pos_norm*vi_pos_norm\n",
    "        norm_neg=ui_neg_norm*vi_neg_norm\n",
    "        \n",
    "        if norm_pos>=norm_neg:\n",
    "            w[:,i]=np.sqrt(s[i]*norm_pos)/ui_pos_norm*ui_pos\n",
    "            h[i,:]=np.sqrt(s[i]*norm_pos)/vi_pos_norm*vi_pos.T\n",
    "        else:\n",
    "            w[:,i]=np.sqrt(s[i]*norm_neg)/ui_neg_norm*ui_neg\n",
    "            h[i,:]=np.sqrt(s[i]*norm_neg)/vi_neg_norm*vi_neg.T\n",
    "\n",
    "    return w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mur_optimization_RNMF( X, k, max_iteration, init_mode):\n",
    "\n",
    "#     #X_c = the X with clean data\n",
    "#     #X is the polluted data\n",
    "\n",
    "\n",
    "#     #U.shape is m * k,  V.shape is k * n\n",
    "#     #m = numbers of features/ elements of 1 column vector of X.\n",
    "#     #n is the numbers of training examples\n",
    "\n",
    "#     #TODO\n",
    "\n",
    "#     #implement earlier stop\n",
    "\n",
    "\n",
    "#     #X should be \n",
    "\n",
    "#     if init_mode == 'random':\n",
    "#         U ,V = random_initialization(X_c,k)    \n",
    "#     elif init_mode == 'nndsvd':\n",
    "#         U ,V = nndsvd_initialization(X_c,k) \n",
    "\n",
    "    \n",
    "#     error = []\n",
    "\n",
    "#     e = 1.0e-10\n",
    "\n",
    "#     for iter in range(max_iteration):\n",
    "\n",
    "#         #update U\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mur_optimization_nmf_stock(X, k, max_iter, init_mode):\n",
    "\n",
    "    if init_mode == 'random':\n",
    "        U ,V = random_initialization(X, k)\n",
    "    elif init_mode == 'nndsvd':\n",
    "        U ,V = nndsvd_initialization(X, k) \n",
    "\n",
    "\n",
    "    loss_iter = []\n",
    "\n",
    "\n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        #update V\n",
    "        U_tX = U.T @ X\n",
    "        U_tUV = U.T @ U @ V\n",
    "\n",
    "        for i in range(np.size(V, 0)): #i row\n",
    "            for j in range(np.size(V, 1)): #j column\n",
    "                V[i,j] = V[i,j] * U_tX[i,j] / U_tUV[i,j]\n",
    "\n",
    "\n",
    "        #update U\n",
    "        XV_t = X @ V.T\n",
    "        UVV_t = U @ V @ V.T\n",
    "\n",
    "        for i in range(np.size(U, 0)): #i row\n",
    "            for j in range(np.size(U, 1)): #j column\n",
    "                U[i,j] = U[i,j] * XV_t[i,j] / UVV_t[i,j]\n",
    "\n",
    "        \n",
    "        loss = np.linalg.norm(X - (U @ V), 'fro' )  #Frobenius norm, by default\n",
    "        loss_iter.append(loss)\n",
    "    \n",
    "\n",
    "    return U, V, loss_iter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mur_optimization_robust_nmf_l1(X, k, reg_lambda, max_iter, init_mode):\n",
    "    \n",
    "    if init_mode == 'random':\n",
    "        U ,V = random_initialization(X, k)\n",
    "    elif init_mode == 'nndsvd':\n",
    "        U ,V = nndsvd_initialization(X, k) \n",
    "\n",
    "\n",
    "    #generate E\n",
    "\n",
    "    #method 1\n",
    "    # E is initialized with all zeros\n",
    "    #E = np.zeros(X.shape)\n",
    "\n",
    "    #method 2\n",
    "    # E = X - UV\n",
    "    E = X - (U @ V)\n",
    "\n",
    "    \n",
    "\n",
    "    loss_iter = []\n",
    "\n",
    "    \n",
    "    for iter in range(max_iter):\n",
    "\n",
    "\n",
    "        # update U\n",
    "\n",
    "        #get X^\n",
    "        X_hat = np.subtract(X,E)\n",
    "\n",
    "        #check negative constrain  X - E >= 0\n",
    "        if X_hat.sum() <= 0:\n",
    "            print(\"Error, noise is greater than X\")\n",
    "\n",
    "\n",
    "        X_hat_V_t = X_hat @ V.T\n",
    "        UVV_t = U @ V @ V.T\n",
    "\n",
    "        for i in range(np.size(U, 0)): #i row\n",
    "            for j in range(np.size(U,1)): #j column\n",
    "                U[i,j] = U[i,j] * X_hat_V_t[i,j] / UVV_t[i,j]\n",
    "        \n",
    "\n",
    "        # update V, E simultaneously\n",
    "\n",
    "        E_p = (np.absolute(E) + E) / 2\n",
    "\n",
    "        E_n = (np.absolute(E) - E) / 2\n",
    "\n",
    "\n",
    "        #compute V dash\n",
    "        V_dash = np.concatenate((V, E_p, E_n), axis=0)\n",
    "\n",
    "\n",
    "        #compute X dash\n",
    "        X_dash = np.concatenate( ( X, np.zeros((1, X.shape[1])) ), axis=0)\n",
    "\n",
    "\n",
    "        #compute U dash\n",
    "        U_1 = np.concatenate( ( U, np.zeros((1,U.shape[1])) ), axis=0)\n",
    "\n",
    "        reg_parameter = np.sqrt(reg_lambda) * np.exp(1)\n",
    "\n",
    "        arr_below_I = np.full( (1, U.shape[0]),  reg_parameter)\n",
    "\n",
    "        I_U = np.concatenate( (np.identity(U.shape[0]), arr_below_I ), axis=0 )\n",
    "\n",
    "        N_I_U = np.concatenate( (  (-1)*(np.identity(U.shape[0])) , arr_below_I ), axis=0 )\n",
    "\n",
    "        U_dash = np.concatenate( (U_1, I_U, N_I_U), axis=1  )\n",
    "        \n",
    "\n",
    "        #compute S\n",
    "        S = np.absolute( U_dash.T * U_dash )\n",
    "\n",
    "\n",
    "        #load precomputed parameter\n",
    "\n",
    "        SV_dash = S @ V_dash\n",
    "\n",
    "        U_d_t_U_d_V_d = U_dash.T @ U_dash @ V_dash\n",
    "\n",
    "        U_d_t_X_d = U_dash.T @ X_dash\n",
    "\n",
    "\n",
    "        #update V_dash\n",
    "\n",
    "        for i in range(np.size(V_dash, 0)): #i column\n",
    "            for j in range(np.size(V_dash, 1)): #j column\n",
    "                \n",
    "                # compute the result\n",
    "                result = V_dash[i,j] - ( (V_dash[i,j] * U_d_t_U_d_V_d[i,j]) / SV_dash[i,j] ) + (  (V_dash[i,j] * U_d_t_X_d[i,j] ) / SV_dash[i,j] )\n",
    "                #nmf update\n",
    "                V_dash[i,j] = max(0, result)\n",
    "\n",
    "        \n",
    "\n",
    "        #update actual V and E\n",
    "        V = V_dash[ : V.shape[0] ,:]\n",
    "        \n",
    "        E_p = V_dash[ V.shape[0] : V.shape[0] + E.shape[0] ,:]\n",
    "        E_n = V_dash[ V.shape[0] + E.shape[0] : ,:]\n",
    "\n",
    "        E = E_p - E_n\n",
    "\n",
    "\n",
    "\n",
    "        #update the loss\n",
    "        loss = np.linalg.norm( X - (U @ V) - E , ord='fro')\n",
    "        print(\"Current Iteration : \", iter, \"   Loss : \", loss)\n",
    "\n",
    "        loss_iter.append(loss)\n",
    "\n",
    "\n",
    "        #TODO\n",
    "        #add earlier stop mechanism\n",
    "\n",
    "\n",
    "\n",
    "    return U, V, E, loss_iter\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9283156  0.05113315 0.73918679]\n",
      " [0.23930001 0.9747538  0.1314771 ]\n",
      " [0.83628397 0.11115882 0.02203652]] 4.033645759663626 (3, 3)\n",
      "[[0.9283156  0.05113315 0.73918679]\n",
      " [0.23930001 0.9747538  0.1314771 ]]\n",
      "[[ 0.50233019 -0.24670821 -0.01418923]\n",
      " [ 0.15158295  0.26941201 -0.06999503]\n",
      " [-0.11888058 -0.78192692 -0.6971055 ]] -1.0054803197534308 (3, 3)\n",
      "[[1.00466039 0.49341641 0.02837846]\n",
      " [0.30316589 0.53882401 0.13999006]\n",
      " [0.23776116 1.56385385 1.39421099]] (3, 3)\n",
      "[[1.00466039 0.49341641 0.02837846]\n",
      " [0.30316589 0.53882401 0.13999006]\n",
      " [0.23776116 1.56385385 1.39421099]]\n",
      "[[-0.9283156  -0.05113315 -0.73918679]\n",
      " [-0.23930001 -0.9747538  -0.1314771 ]\n",
      " [-0.83628397 -0.11115882 -0.02203652]\n",
      " [-0.4259854  -0.29784135 -0.75337602]\n",
      " [-0.08771706 -0.7053418  -0.20147213]\n",
      " [-0.95516455 -0.89308575 -0.71914202]\n",
      " [-0.50233019  0.24670821  0.01418923]\n",
      " [-0.15158295 -0.26941201  0.06999503]\n",
      " [ 0.11888058  0.78192692  0.6971055 ]\n",
      " [-0.         -0.         -0.        ]] (10, 3)\n",
      "[[0.9283156  0.05113315 0.73918679]\n",
      " [0.23930001 0.9747538  0.1314771 ]\n",
      " [0.83628397 0.11115882 0.02203652]]\n"
     ]
    }
   ],
   "source": [
    "print( (-1) * np.identity(3))\n",
    "\n",
    "X = np.random.random((3,3))\n",
    "print(X, X.sum(), X.shape)\n",
    "print( X[: X.shape[0]  , : ] )\n",
    "\n",
    "Y = np.random.random(X.shape)\n",
    "\n",
    "r = np.subtract(X, Y)\n",
    "\n",
    "abs_r = np.absolute(r)\n",
    "\n",
    "#print(Y, Y.sum(), Y.shape)\n",
    "\n",
    "print(r, r.sum(), r.shape)\n",
    "print(abs_r + abs_r, abs_r.shape)\n",
    "print(abs_r * 2)\n",
    "\n",
    "\n",
    "c = np.concatenate((X,Y,r, np.zeros((1, X.shape[1]))), axis=0)\n",
    "c = c * -1\n",
    "print(c, c.shape)\n",
    "\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7ab4b668b9c3253ac8de087697e889de689ad4be6a3547b9edfeb441b24f2d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
